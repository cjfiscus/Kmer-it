import pandas as pd
from snakemake.utils import min_version
min_version("5.3.0")

# set up config
configfile: "config/config.yaml"
samples = pd.read_table("config/samples.tsv").set_index("id", drop=False)
all_ids=list(samples["id"])

rule all:
    input:
        "results/count_tbl_gc_qq.txt.gz"

if config["normalization"]["gc_correct"] == True:
    rule calc_gc:
        """
	calc GC bins per sample
	"""
        input:
            "results/counts/{id}.txt.gz"
        output:
            "results/counts/gc/{id}.txt"
        shell:
            """
            python scripts/calc_gc.py {input} > {output}
            """

    rule gc_correct:
        input:
            "results/count_tbl.txt.gz",
	    expand("results/counts/gc/{id}.txt", id=all_ids)
        output:
            "results/count_tbl_gc.txt.gz"
        shell:
            """
            cat results/counts/gc/*.txt > results/allgc.txt
	    Rscript scripts/calc_ref_gc_bins.R results/allgc.txt results/gc_ref.txt

	    Rscript scripts/gc_correct_tbl.R {input[0]} {output} results/allgc.txt results/gc_ref.txt
	    """
else:
    rule skip_gc_correct:
        input:
	    "results/count_tbl.txt.gz"
        output:
	    "results/count_tbl_gc.txt.gz"
            shell:
                """
		ln -sr {input} {output}
                """

if config["normalization"]["cov_norm"] == True:
    rule cov_norm:
        input:
            "results/count_tbl_gc.txt.gz"
        output:
            "results/count_tbl_gc_qq.txt.gz"
        shell:
            """
	    Rscript scripts/norm_qq.R {input} {output}
	    """
else:
    rule skip_cov_norm:
        input:
            "results/count_tbl_gc.txt.gz"
        output:
            "results/count_tbl_gc_cov.txt.gz"
        shell:
            """
	    ln -sr {input} {output}
	    """

rule join_kmers:
    input:
        expand("results/counts/{id}.txt.gz", id=all_ids)
    output:
        "results/count_tbl.txt.gz"
    shell:
        """
        bash scripts/mk_count_tbl.sh {input} {output}
	"""

if config["map_to_organellar_genomes"]["use_custom_org_genome"] == True:
    rule index_custom_genome:
        """
        copy custom genome to resources and index
        """
        params:
            path=config["map_to_organellar_genomes"]["custom_org_genome_path"]
        output:
            "resources/org_genomes.fa",
            expand("resources/org_genomes.fa.{ext}", ext=["ann", "bwt", "pac", "sa"])
        shell:
            """
            # copy custom genome to resources
            cp {params.path} resources/org_genomes.fa

            # index with bwa
            bwa index resources/org_genomes.fa
            """

else:
    rule build_organellar_genome_db:
        """
        Download and format Organellar Genomes from NCBI Organelle Genome Resources
        """
        output:
            "resources/org_genomes.fa", 
            expand("resources/org_genomes.fa.{ext}", ext=["ann", "bwt", "pac", "sa"])
        shell:
            """
            # dl refseq from ncbi
            wget -nd -np -r -A 'mitochondrion.*.*.genomic.fna.gz' ftp://ftp.ncbi.nlm.nih.gov/refseq/release/mitochondrion/
            wget -nd -np -r -A 'plastid.*.*.genomic.fna.gz' ftp://ftp.ncbi.nlm.nih.gov/refseq/release/plastid/

            # combine files
            gunzip -c *.fna.gz > resources/org_genomes.fa        

            # index with bwa
            bwa index resources/org_genomes.fa 
        
            # cleanup 
            rm mitochondrion.*.*.genomic.fna.gz
            rm plastid.*.*.genomic.fna.gz       
            """

ruleorder: ln_fastq_pe > ln_fastq_se > dl_fastq_pe > dl_fastq_se
rule ln_fastq_pe:
    """
    link pe reads files
    """
    input:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"],
        fq2=lambda wildcards: samples.loc[wildcards.id, "fq2"] if "fq2" in samples else "non-existing-filename"
    output:
        "resources/pe/raw/{id}_1.fq.gz",
        "resources/pe/raw/{id}_2.fq.gz"
    run:
        #print(f"Starting ln_fastq_pe with input: {input} and output: {output}")
        shell("ln -sr {input.fq1} {output[0]}")
        shell("ln -sr {input.fq2} {output[1]}")

rule dl_fastq_pe:
    """
    download pe reads files
    """
    params:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"],
	fq2=lambda wildcards: samples.loc[wildcards.id, "fq2"] if "fq2" in samples else "non-existing filename"
    output:
        "resources/pe/raw/{id}_1.fq.gz",
	"resources/pe/raw/{id}_2.fq.gz"
    shell:
        """
	wget --no-check-certificate -O {output[0]} {params.fq1}
	wget --no-check-certificate -O {output[1]} {params.fq2}
	"""

rule rule ln_fastq_se:
    """
    link se reads file
    """
    input:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"]
    output:
        "resources/se/raw/{id}.fq.gz",
    shell:
        """
        ln -sr {input.fq1} {output}
        """

rule dl_fastq_se:
    """
    download se reads file
    """
    params:
        fq=lambda wildcards: samples.loc[wildcards.id, "fq1"]
    output:
        "resources/se/raw/{id}.fq.gz"
    shell:
        """
	wget --no-check-certificate -O {output} {params.fq}
	"""

if config["trimming"]["enable"] == True:
    ruleorder: trim_reads_pe > trim_reads_se
    rule trim_reads_pe:
        """
        trim adapters and low quality sequence with trimmomatic for pe runs
        """
        input:
            "resources/pe/raw/{id}_1.fq.gz",
            "resources/pe/raw/{id}_2.fq.gz"
        output:
            temp("results/pe/trim/{id}_1_trimmed.fq.gz"),
            temp("results/pe/trim/{id}_1_trimmed_unpaired.fq.gz"),
            temp("results/pe/trim/{id}_2_trimmed.fq.gz"),
            temp("results/pe/trim/{id}_2_trimmed_unpaired.fq.gz")
        params:
            trim_params = config["trimming"]["trimmomatic_pe"]
        threads: 3
        shell:
            """
            echo "trimming with trimmomatic..."
            trimmomatic PE -threads {threads} \
            {input[0]} {input[1]} \
            {output[0]} {output[1]} \
            {output[2]} {output[3]} \
            {params.trim_params}
            """

    rule trim_reads_se:
        """
        trim adapters and low quality sequence with trimmomatic for se runs
        """
        input:
            "resources/se/raw/{id}.fq.gz"
        output:
            temp("results/se/trim/{id}_trimmed.fq.gz")
        params:
            trim_params = config["trimming"]["trimmomatic_se"]
        threads: 3
        shell:
            """
            echo "trimming with trimmomatic..."
            trimmomatic SE -threads {threads} \
            {input} {output} \
            {params.trim_params}
            """
else:
    ruleorder: skip_trimming_pe > skip_trimming_se
    rule skip_trimming_pe:
        """
        skip trimming for pe reads
        """
        input:
            "resources/pe/raw/{id}_1.fq.gz",
            "resources/pe/raw/{id}_2.fq.gz"
        output:
            temp("results/pe/trim/{id}_1_trimmed.fq.gz"),
            temp("results/pe/trim/{id}_2_trimmed.fq.gz")
        shell:
            """
            ln -sr {input[0]} {output[0]}
            ln -sr {input[1]} {output[1]}
            """
	
    rule skip_trimming_se:
        """
        skip trimming for se reads
        """
        input:
            "resources/se/raw/{id}.fq.gz"
        output:
            temp("results/se/trim/{id}_trimmed.fq.gz")
        shell:
            """
            ln -sr {input} {output}
            """

if config["error_correct"]["enable"] == True:
    ruleorder: correct_reads_pe > correct_reads_se
    rule correct_reads_pe:
        """
        correct likely base calling errors using bayeshammer
        """
        input:
            "results/pe/trim/{id}_1_trimmed.fq.gz",
            "results/pe/trim/{id}_2_trimmed.fq.gz"
        output:
            "results/pe/corr/{id}_1_trimmed_ec.fq.gz",
            "results/pe/corr/{id}_2_trimmed_ec.fq.gz",
        threads: 3
        shell:
            """
            spades.py -t {threads} -m 64 --only-error-correction \
            -1 {input[0]} \
            -2 {input[1]} -o ./results/{wildcards.id}

            mv results/{wildcards.id}/corrected/{wildcards.id}_1_trimmed.fq.00.0_0.cor.fastq.gz {output[0]}
            mv results/{wildcards.id}/corrected/{wildcards.id}_2_trimmed.fq.00.0_0.cor.fastq.gz {output[1]}
            """

    rule correct_reads_se:
        """
        correct likely base calling errors with bayeshammer
        """
        input:
            "results/se/trim/{id}_trimmed.fq.gz"
        output:
            "results/se/corr/{id}_trimmed_ec.fq.gz"
        threads: 3
        shell:
            """
            spades.py -t {threads} -m 64 --only-error-correction \
            -s {input} -o ./results

            mv results/corrected/{wildcards.id}_trimmed.fq.00.0_0.cor.fastq.gz {output} 
            """
else:
    ruleorder: skip_correct_reads_pe > skip_correct_reads_se
    rule skip_correct_reads_pe:
        """
        skip error correction for pe reads
        """
        input:
            "results/pe/trim/{id}_1_trimmed.fq.gz",
            "results/pe/trim/{id}_2_trimmed.fq.gz"
        output:
            "results/pe/corr/{id}_1_trimmed_ec.fq.gz",
            "results/pe/corr/{id}_2_trimmed_ec.fq.gz"
        shell:
            """
            ln -sr {input[0]} {output[0]}
            ln -sr {input[1]} {output[1]}
            """
	
    rule skip_correct_reads_se:
        """
        skip error correction for se reads
        """
        input:
            "results/se/trim/{id}_trimmed.fq.gz"
        output:
            "results/se/corr/{id}_trimmed_ec.fq.gz"
        shell:
            """
            ln -sr {input} {output}
            """

if config["map_to_organellar_genomes"]["enable"] == True:
    ruleorder: map_to_organelle_genomes_pe > map_to_organelle_genomes_se
    rule map_to_organelle_genomes_pe:
        """
        map reads to organellar genomes
        """
        input:
            "resources/org_genomes.fa",
            "results/pe/corr/{id}_1_trimmed_ec.fq.gz",
            "results/pe/corr/{id}_2_trimmed_ec.fq.gz"
        output:
            temp("results/alignments/{id}.sam")
        threads: 4
        shell:
            """
            bwa mem -t {threads} -M {input} > {output}
            """

    rule map_to_organelle_genomes_se:
        """
        map reads to organelle genome
        """
        input:
            "resources/org_genomes.fa",
	    "results/se/corr/{id}_trimmed_ec.fq.gz"
        output:
            temp("results/alignments/{id}.sam")
        threads: 4
        shell:
            """
	    bwa mem -t {threads} -M {input} > {output}
	    """
    rule sam_2_sorted_bam_unmapped:
        """
        convert sam to sorted bam, then subset bam for unmapped reads
        """
	input:
            "results/alignments/{id}.sam"
        output:
            temp("results/unmapped/{id}.unmapped.bam")
        shell:
            """
            samtools view -bS {input} | samtools sort -T {wildcards.id} - | samtools view -f4 -b - > {output}
            """

    rule extract_unmapped_reads:
        """
        extract unmapped reads from bam
        """
        input: 
            "results/unmapped/{id}.unmapped.bam"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            bedtools bamtofastq -i {input} -fq {output}
            """
else:
    ruleorder: skip_mapping_pe > skip_mapping_se
    rule skip_mapping_pe:
        """
        skip mapping 
        """
        input: 
            "results/pe/corr/{id}_1_trimmed_ec.fq.gz",
            "results/pe/corr/{id}_2_trimmed_ec.fq.gz"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            gunzip -c {input} > {output}
            """

    rule skip_mapping_se:
        """
        skip mapping
        """
        input:
            "results/se/corr/{id}_trimmed_ec.fq.gz"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            gunzip -c {input} > {output}
            """

rule count_kmers:
    """
    count kmers in seq reads
    """
    input:
        "results/unmapped/{id}.unmapped.fq"
    output:
        temp("results/counts/{id}.jf"),
        "results/counts/{id}.txt.gz"
    params:
        k=config['k'] 
    threads: 16
    shell:
        """
        jellyfish count -C -m {params.k} -s 500M -t {threads} -o {output[0]} {input}

        jellyfish dump -tc {output[0]} | gzip > {output[1]}
        """
