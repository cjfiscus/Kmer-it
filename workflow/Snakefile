import pandas as pd
from snakemake.utils import min_version
min_version("5.3.0")

# set up config
configfile: "config/config.yaml"
samples = pd.read_table("config/samples.tsv").set_index("id", drop=False)
all_ids=list(samples["id"])

rule all:
    input:
        "results/count_tbl_gc_cov.txt",
        expand("results/corrected/{id}_1_trimmed_ec.fq.gz", id=samples.query('end == "PE"').id),
        expand("results/corrected/{id}_trimmed_ec.fq.gz", id=samples.query('end == "SE"').id),
        expand("results/trimmed/{id}_1_trimmed.fq.gz", id=samples.query('end == "PE"').id),
        expand("results/trimmed/{id}_trimmed.fq.gz", id=samples.query('end == "SE"').id)

if config["normalization"]["gc_correct"] == True:
    rule gc_correct:
        input:
            "results/count_tbl.txt"
        output:
            "results/count_tbl_gc.txt"
        shell:
            """
	    Rscript 005a_gc_correct.R "$FILTERED" "$GCNORM" "$REF_PROP_TABLE" "$PROP_TABLE"
	    """
else:
    rule skip_gc_correct:
        input:
	    "results/count_tbl.txt"
        output:
	    "results/count_tbl_gc.txt"
            shell:
                """
		ln -sr {input} {output}
                """

if config["normalization"]["cov_norm"] == True:
    rule cov_norm:
        input:
            "results/count_tbl_gc.txt"
        output:
            "results/count_tbl_gc_cov.txt"
        shell:
            """
	    Rscript 005b_rle.R "$GCNORM" "$GCTMMNORM"
	    """
else:
    rule skip_cov_norm:
        input:
            "results/count_tbl_gc.txt"
        output:
            "results/count_tbl_gc_cov.txt"
        shell:
            """
	    ln -sr {input} {output}
	    """

rule join_kmers:
    input:
        expand("results/counts/{id}.txt.gz", id=all_ids)
    output:
        "results/count_tbl.txt"
    shell:
        """
	# def function for join
	joinm() {
        f1=$1; f2=$2; shift 2;
        if [ $# -gt 0 ]
        then
        # join files
        join -a 1 -a 2 -e 0 "$f1" "$f2" -o auto -t $'\t' | joinm - "$@"

        else
        # join 2 files
        join -a 1 -a 2 -e 0 "$f1" "$f2" -o auto -t $'\t'

        fi
        }

        ## join counts across samples
        joinm results/counts/*.txt > temp.tmp

        ## make header
	HEADER=$(echo "mer")
        NUM=$(ls results/counts/*.txt | wc -l)

        for i in `seq 1 $NUM`
        do
        NAME=$(ls results/counts/*.txt | head -n $i | tail -n1)
        NAME=$(basename "$NAME" | cut -d. -f1)
        HEADER=$(echo "$HEADER""\t""$NAME")
        done

        # add header to file
        sed '1s/^/'"$HEADER"'\n/' temp.tmp > results/count_tbl.txt

        ## cleanup
        rm temp.tmp
	"""

if config["map_to_organellar_genomes"]["use_custom_org_genome"] == True:
    rule index_custom_genome:
        """
        copy custom genome to resources and index
        """
        params:
            path=config["map_to_organellar_genomes"]["custom_org_genome_path"]
        output:
            "resources/org_genomes.fa",
            expand("resources/org_genomes.fa.{ext}", ext=["ann", "bwt", "pac", "sa"])
        shell:
            """
            # copy custom genome to resources
            cp {params.path} resources/org_genomes.fa

            # index with bwa
            bwa index resources/org_genomes.fa
            """

else:
    rule build_organellar_genome_db:
        """
        Download and format Organellar Genomes from NCBI Organelle Genome Resources
        """
        output:
            "resources/org_genomes.fa", 
            expand("resources/org_genomes.fa.{ext}", ext=["ann", "bwt", "pac", "sa"])
        shell:
            """
            # dl refseq from ncbi
            wget -nd -np -r -A 'mitochondrion.*.*.genomic.fna.gz' ftp://ftp.ncbi.nlm.nih.gov/refseq/release/mitochondrion/
            wget -nd -np -r -A 'plastid.*.*.genomic.fna.gz' ftp://ftp.ncbi.nlm.nih.gov/refseq/release/plastid/

            # combine files
            gunzip -c *.fna.gz > resources/org_genomes.fa        

            # index with bwa
            bwa index resources/org_genomes.fa 
        
            # cleanup 
            rm mitochondrion.*.*.genomic.fna.gz
            rm plastid.*.*.genomic.fna.gz       
            """

ruleorder: ln_fastq_pe > ln_fastq_se > dl_fastq_pe > dl_fastq_se
rule ln_fastq_pe:
    """
    link pe reads files
    """
    input:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"],
        fq2=lambda wildcards: samples.loc[wildcards.id, "fq2"] if "fq2" in samples else "non-existing-filename"
    output:
        "resources/fq/{id}_1.fq.gz",
        "resources/fq/{id}_2.fq.gz"
    run:
        #print(f"Starting ln_fastq_pe with input: {input} and output: {output}")
        shell("ln -sr {input.fq1} {output[0]}")
        shell("ln -sr {input.fq2} {output[1]}")

rule dl_fastq_pe:
    """
    download pe reads files
    """
    params:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"],
	fq2=lambda wildcards: samples.loc[wildcards.id, "fq2"] if "fq2" in samples else "non-existing filename"
    output:
        "resources/fq/{id}_1.fq.gz",
	"resources/fq/{id}_2.fq.gz"
    shell:
        """
	wget --no-check-certificate -O {output[0]} {params.fq1}
	wget --no-check-certificate -O {output[1]} {params.fq2}
	"""

rule rule ln_fastq_se:
    """
    link se reads file
    """
    input:
        fq1=lambda wildcards: samples.loc[wildcards.id, "fq1"]
    output:
        "resources/fq/{id}.fq.gz",
    shell:
        """
        ln -sr {input.fq1} {output}
        """

rule dl_fastq_se:
    """
    download se reads file
    """
    params:
        fq=lambda wildcards: samples.loc[wildcards.id, "fq1"]
    output:
        "resources/fq/{id}.fq.gz"
    shell:
        """
	wget --no-check-certificate -O {output} {params.fq}
	"""

if config["trimming"]["enable"] == True:
    ruleorder: trim_reads_pe > trim_reads_se
    rule trim_reads_pe:
        """
        trim adapters and low quality sequence with trimmomatic for pe runs
        """
        input:
            "resources/fq/{id}_1.fq.gz",
            "resources/fq/{id}_2.fq.gz"
        output:
            temp("results/trimmed/{id}_1_trimmed.fq.gz"),
            temp("results/trimmed/{id}_1_trimmed_unpaired.fq.gz"),
            temp("results/trimmed/{id}_2_trimmed.fq.gz"),
            temp("results/trimmed/{id}_2_trimmed_unpaired.fq.gz")
        params:
            trim_params = config["trimming"]["trimmomatic_pe"]
        threads: 3
        shell:
            """
            echo "trimming with trimmomatic..."
            trimmomatic PE -threads {threads} \
            {input[0]} {input[1]} \
            {output[0]} {output[1]} \
            {output[2]} {output[3]} \
            {params.trim_params}
            """

    rule trim_reads_se:
        """
        trim adapters and low quality sequence with trimmomatic for se runs
        """
        input:
            "resources/fq/{id}.fq.gz"
        output:
            temp("results/trimmed/{id}_trimmed.fq.gz")
        params:
            trim_params = config["trimming"]["trimmomatic_se"]
        threads: 3
        shell:
            """
            echo "trimming with trimmomatic..."
            trimmomatic SE -threads {threads} \
            {input} {output} \
            {params.trim_params}
            """
else:
    ruleorder: skip_trimming_pe > skip_trimming_se
    rule skip_trimming_pe:
        """
        skip trimming for pe reads
        """
        input:
            "resources/fq/{id}_1.fq.gz",
            "resources/fq/{id}_2.fq.gz"
        output:
            temp("results/trimmed/{id}_1_trimmed.fq.gz"),
            temp("results/trimmed/{id}_2_trimmed.fq.gz")
        shell:
            """
            ln -sr {input[0]} {output[0]}
            ln -sr {input[1]} {output[1]}
            """
	
    rule skip_trimming_se:
        """
        skip trimming for se reads
        """
        input:
            "resources/fq/{id}.fq.gz"
        output:
            temp("results/trimmed/{id}_trimmed.fq.gz")
        shell:
            """
            ln -sr {input} {output}
            """

if config["error_correct"]["enable"] == True:
    ruleorder: correct_reads_pe > correct_reads_se
    rule correct_reads_pe:
        """
        correct likely base calling errors using bayeshammer
        """
        input:
            "results/trimmed/{id}_1_trimmed.fq.gz",
            "results/trimmed/{id}_2_trimmed.fq.gz"
        output:
            "results/corrected/{id}_1_trimmed_ec.fq.gz",
            "results/corrected/{id}_2_trimmed_ec.fq.gz",
        threads: 3
        shell:
            """
            spades.py -t {threads} -m 64 --only-error-correction \
            -1 {input[0]} \
            -2 {input[1]} -o ./results

            mv results/corrected/{wildcards.id}_1_trimmed_ec.fq.00.0_0.cor.fastq.gz {output[0]}
            mv results/corrected/{wildcards.id}_2_trimmed_ec.fq.00.0_0.cor.fastq.gz {output[1]}
            """

    rule correct_reads_se:
        """
        correct likely base calling errors with bayeshammer
        """
        input:
            "results/trimmed/{id}_trimmed.fq.gz"
        output:
            "results/corrected/{id}_trimmed_ec.fq.gz"
        threads: 3
        shell:
            """
            spades.py -t {threads} -m 64 --only-error-correction \
            -s {input} -o ./results

            mv results/corrected/{wildcards.id}_trimmed.fq.00.0_0.cor.fastq.gz {output} 
            """
else:
    ruleorder: skip_correct_reads_pe > skip_correct_reads_se
    rule skip_correct_reads_pe:
        """
        skip error correction for pe reads
        """
        input:
            "results/trimmed/{id}_1_trimmed.fq.gz",
            "results/trimmed/{id}_2_trimmed.fq.gz"
        output:
            "results/corrected/{id}_1_trimmed_ec.fq.gz",
            "results/corrected/{id}_2_trimmed_ec.fq.gz"
        shell:
            """
            ln -sr {input[0]} {output[0]}
            ln -sr {input[1]} {output[1]}
            """
	
    rule skip_correct_reads_se:
        """
        skip error correction for se reads
        """
        input:
            "results/trimmed/{id}_trimmed.fq.gz"
        output:
            "results/corrected/{id}_trimmed_ec.fq.gz"
        shell:
            """
            ln -sr {input} {output}
            """

if config["map_to_organellar_genomes"]["enable"] == True:
    ruleorder: map_to_organelle_genomes_pe > map_to_organelle_genomes_se
    rule map_to_organelle_genomes_pe:
        """
        map reads to organellar genomes
        """
        input:
            "resources/org_genomes.fa",
            "results/corrected/{id}_1_trimmed_ec.fq.gz",
            "results/corrected/{id}_2_trimmed_ec.fq.gz"
        output:
            temp("results/alignments/{id}.sam")
        threads: 4
        shell:
            """
            bwa mem -t {threads} -M {input} > {output}
            """

    rule map_to_organelle_genomes_se:
        """
        map reads to organelle genome
        """
        input:
            "resources/org_genomes.fa",
	    "results/corrected/{id}_trimmed_ec.fq.gz"
        output:
            temp("results/alignments/{id}.sam")
        threads: 4
        shell:
            """
	    bwa mem -t {threads} -M {input} > {output}
	    """
    rule sam_2_sorted_bam_unmapped:
        """
        convert sam to sorted bam, then subset bam for unmapped reads
        """
	input:
            "results/alignments/{id}.sam"
        output:
            temp("results/unmapped/{id}.unmapped.bam")
        shell:
            """
            samtools view -bS {input} | samtools sort -T {wildcards.id} - | samtools view -f4 -b - > {output}
            """

    rule extract_unmapped_reads:
        """
        extract unmapped reads from bam
        """
        input: 
            "results/unmapped/{id}.unmapped.bam"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            bedtools bamtofastq -i {input} -fq {output}
            """
else:
    ruleorder: skip_mapping_pe > skip_mapping_se
    rule skip_mapping_pe:
        """
        skip mapping 
        """
        input: 
            "results/corrected/{id}_1_trimmed_ec.fq.gz",
            "results/corrected/{id}_2_trimmed_ec.fq.gz"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            gunzip -c {input} > {output}
            """

    rule skip_mapping_se:
        """
        skip mapping
        """
        input:
            "results/corrected/{id}_trimmed_ec.fq.gz"
        output:
            temp("results/unmapped/{id}.unmapped.fq")
        shell:
            """
            gunzip -c {input} > {output}
            """

rule count_kmers:
    """
    count kmers in seq reads
    """
    input:
        "results/unmapped/{id}.unmapped.fq"
    output:
        temp("results/counts/{id}.jf"),
        "results/counts/{id}.txt.gz"
    params:
        k=config['k'] 
    threads: 16
    shell:
        """
        jellyfish count -C -m {params.k} -s 500M -t {threads} -o {output[0]} {input}

        jellyfish dump -tc {output[0]} | gzip > {output[1]}
        """
